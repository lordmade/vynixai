<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vynix AI Chatbot</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            min-height: 100vh;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            display: flex;
            flex-direction: column;
            overflow: auto;
            background-image: radial-gradient(circle, rgba(255, 255, 255, 0.1) 1px, transparent 1px);
            background-size: 20px 20px;
        }

        .header {
            text-align: center;
            padding: 15px;
            background: rgba(0, 0, 0, 0.3);
            position: sticky;
            top: 0;
            z-index: 10;
        }

        h1 {
            font-size: 1.6em;
            margin: 0;
            color: #00d4ff;
            text-shadow: 0 0 10px rgba(0, 212, 255, 0.5);
        }

        .chat-box {
            flex: 1;
            overflow-y: auto;
            padding: 10px;
            padding-bottom: 80px; /* Space for floating input */
        }

        .message {
            display: flex;
            flex-direction: column;
            margin: 8px 10px;
            padding: 8px 12px;
            border-radius: 12px;
            max-width: 70%;
            word-wrap: break-word;
            animation: fadeIn 0.3s ease-in;
        }

        .user-message {
            background: linear-gradient(45deg, #007bff, #00d4ff);
            color: white;
            margin-left: auto;
            border-top-right-radius: 2px;
        }

        .ai-message {
            background: rgba(255, 255, 255, 0.1);
            color: #e0e0e0;
            margin-right: auto;
            border-top-left-radius: 2px;
        }

        .timestamp {
            font-size: 0.7em;
            color: rgba(255, 255, 255, 0.6);
            align-self: flex-end;
            margin-top: 4px;
        }

        .input-container {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            display: flex;
            gap: 8px;
            background: rgba(0, 0, 0, 0.4);
            padding: 8px 10px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(5px);
            z-index: 10;
        }

        input {
            flex: 1;
            padding: 10px;
            border: none;
            border-radius: 20px;
            background: rgba(255, 255, 255, 0.1);
            color: #e0e0e0;
            font-size: 1em;
            outline: none;
        }

        input::placeholder {
            color: rgba(255, 255, 255, 0.5);
        }

        button {
            padding: 10px;
            background: transparent;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .send-icon {
            width: 24px;
            height: 24px;
            background: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="%23e0e0e0"><path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/></svg>') no-repeat center;
            background-size: contain;
        }

        #status {
            font-size: 0.8em;
            color: rgba(255, 255, 255, 0.7);
            text-align: center;
            padding: 8px;
            background: rgba(0, 0, 0, 0.3);
        }

        .loading::after {
            content: '';
            display: inline-block;
            width: 14px;
            height: 14px;
            border: 2px solid #00d4ff;
            border-radius: 50%;
            border-top-color: transparent;
            animation: spin 1s linear infinite;
            margin-left: 8px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @media (max-width: 600px) {
            .header {
                padding: 10px;
            }

            h1 {
                font-size: 1.4em;
            }

            .chat-box {
                padding-bottom: 70px;
            }

            .message {
                max-width: 80%;
            }

            .input-container {
                padding: 6px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Vynix AI - Powered by BanterBox</h1>
    </div>
    <div class="chat-box" id="chatBox"></div>
    <div class="input-container">
        <input type="text" id="userInput" placeholder="Ask Vynix AI something..." />
        <button id="sendButton" onclick="sendMessage()" disabled><span class="send-icon"></span></button>
    </div>
    <p id="status" class="loading">Checking environment...</p>
    <script type="module">
        import { initializeApp } from 'https://www.gstatic.com/firebasejs/11.10.0/firebase-app.js';
        import { getDatabase, ref, get, push } from 'https://www.gstatic.com/firebasejs/11.10.0/firebase-database.js';

        // Firebase configuration (replace with your Firebase project config)
        const firebaseConfig = {
            apiKey: "YOUR_API_KEY",
            authDomain: "YOUR_AUTH_DOMAIN",
            databaseURL: "YOUR_DATABASE_URL",
            projectId: "YOUR_PROJECT_ID",
            storageBucket: "YOUR_STORAGE_BUCKET",
            messagingSenderId: "YOUR_MESSAGING_SENDER_ID",
            appId: "YOUR_APP_ID"
        };

        // Initialize Firebase
        const app = initializeApp(firebaseConfig);
        const database = getDatabase(app);

        // Lazy load TensorFlow.js
        const tfScript = document.createElement('script');
        tfScript.src = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js';
        tfScript.onload = initialize;
        tfScript.onerror = () => {
            document.getElementById('status').innerText = 'Error: Failed to load TensorFlow.js. Please refresh.';
            console.error('Failed to load TensorFlow.js');
        };
        document.head.appendChild(tfScript);

        // Global variables
        let qaModel, textGenModel, chatHistory = [], modelsLoaded = false, userId = 'anonymous_' + Math.random().toString(36).substr(2, 9);

        // Fetch dataset from Firebase
        async function fetchDataset() {
            try {
                document.getElementById('status').innerText = 'Fetching dataset from Firebase...';
                document.getElementById('status').classList.add('loading');
                const snapshot = await get(ref(database, 'dataset'));
                const data = snapshot.val() || { qa: [], textGen: [] };
                return {
                    qa: data.qa || [
                        { question: "What is the capital of France?", answer: "Paris" },
                        { question: "Who wrote Romeo and Juliet?", answer: "William Shakespeare" },
                        { question: "What is the largest planet?", answer: "Jupiter" },
                        { question: "Where is the Great Wall?", answer: "China" },
                        { question: "What is 2 + 2?", answer: "4" }
                    ],
                    textGen: data.textGen || [
                        "The sun sets slowly behind the mountain.",
                        "A curious cat explored the garden.",
                        "Let's meet at the park tomorrow!"
                    ]
                };
            } catch (error) {
                console.error('Firebase dataset fetch error:', error);
                document.getElementById('status').innerText = 'Error fetching dataset. Using default dataset.';
                document.getElementById('status').classList.remove('loading');
                return {
                    qa: [
                        { question: "What is the capital of France?", answer: "Paris" },
                        { question: "Who wrote Romeo and Juliet?", answer: "William Shakespeare" },
                        { question: "What is the largest planet?", answer: "Jupiter" },
                        { question: "Where is the Great Wall?", answer: "China" },
                        { question: "What is 2 + 2?", answer: "4" }
                    ],
                    textGen: [
                        "The sun sets slowly behind the mountain.",
                        "A curious cat explored the garden.",
                        "Let's meet at the park tomorrow!"
                    ]
                };
            }
        }

        // Load chat history from Firebase
        async function loadChatHistory() {
            try {
                const snapshot = await get(ref(database, `chats/${userId}/messages`));
                const messages = snapshot.val() || {};
                chatHistory = Object.values(messages).filter(msg => msg && msg.content && msg.timestamp);
                updateChatBox();
            } catch (error) {
                console.error('Firebase chat load error:', error);
                document.getElementById('status').innerText = 'Error loading chat history.';
            }
        }

        // Save message to Firebase
        async function saveMessageToFirebase(message) {
            try {
                await push(ref(database, `chats/${userId}/messages`), message);
            } catch (error) {
                console.error('Firebase save message error:', error);
                document.getElementById('status').innerText = 'Error saving message to Firebase.';
            }
        }

        // Vocabulary for Q&A
        async function getVocab(dataset) {
            return [...new Set(
                dataset.qa.flatMap(item => item.question.toLowerCase().split(/\s+/))
                    .concat(dataset.qa.flatMap(item => item.answer.toLowerCase().split(/\s+/)))
            )];
        }

        const charVocab = 'abcdefghijklmnopqrstuvwxyz .!?';
        const maxLength = 10; // Max input length for Q&A
        const maxGenLength = 20; // Max input length for text generation
        const confidenceThreshold = 0.7;

        // Preprocess Q&A input
        function preprocessQA(text, vocab) {
            const tokens = text.toLowerCase().split(/\s+/).filter(word => vocab.includes(word));
            const sequence = tokens.map(word => vocab.indexOf(word) + 1).slice(0, maxLength);
            while (sequence.length < maxLength) sequence.push(0);
            return tf.tensor2d([sequence], [1, maxLength], 'int32');
        }

        // Preprocess text generation input
        function preprocessTextGen(text) {
            const chars = text.toLowerCase().split('');
            const sequence = chars.map(c => charVocab.indexOf(c) + 1).slice(0, maxGenLength);
            while (sequence.length < maxGenLength) sequence.push(0);
            return tf.tensor2d([sequence], [1, maxGenLength], 'int32');
        }

        // Create Q&A model (ultra-small)
        function createQAModel(vocabSize, qaLength) {
            const model = tf.sequential();
            model.add(tf.layers.embedding({ inputDim: vocabSize, outputDim: 1, inputLength: maxLength }));
            model.add(tf.layers.lstm({ units: 2 }));
            model.add(tf.layers.dense({ units: qaLength, activation: 'softmax' }));
            model.compile({ optimizer: 'adam', loss: 'sparseCategoricalCrossentropy', metrics: ['accuracy'] });
            return model;
        }

        // Create text generation model (ultra-small)
        function createTextGenModel(charVocabSize) {
            const model = tf.sequential();
            model.add(tf.layers.embedding({ inputDim: charVocabSize, outputDim: 1, inputLength: maxGenLength }));
            model.add(tf.layers.lstm({ units: 3 }));
            model.add(tf.layers.dense({ units: charVocabSize, activation: 'softmax' }));
            model.compile({ optimizer: 'adam', loss: 'sparseCategoricalCrossentropy', metrics: ['accuracy'] });
            return model;
        }

        // Train models
        async function trainModels(dataset) {
            try {
                // Check localStorage
                if (!window.localStorage) {
                    throw new Error('localStorage is not available');
                }

                const vocab = await getVocab(dataset);

                // Train Q&A model
                document.getElementById('status').innerText = 'Training Q&A model...';
                document.getElementById('status').classList.add('loading');
                qaModel = createQAModel(vocab.length + 1, dataset.qa.length);
                const qaInputs = tf.concat(dataset.qa.map(item => preprocessQA(item.question, vocab)));
                const qaOutputs = tf.tensor1d(dataset.qa.map((_, i) => i));
                await qaModel.fit(qaInputs, qaOutputs, {
                    epochs: 5,
                    batchSize: 1,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('status').innerText = `Q&A Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`;
                        }
                    }
                });
                await qaModel.save('localstorage://vynix-qa-model');

                // Train text generation model
                document.getElementById('status').innerText = 'Training text generation model...';
                textGenModel = createTextGenModel(charVocab.length + 1);
                const textInputs = tf.concat(dataset.textGen.map(text => preprocessTextGen(text)));
                const textOutputs = tf.tensor1d(
                    dataset.textGen.map(text => {
                        const chars = text.toLowerCase().split('').slice(1).concat(' ');
                        return chars.map(c => charVocab.indexOf(c) + 1)[0] || 0;
                    })
                );
                await textGenModel.fit(textInputs, textOutputs, {
                    epochs: 5,
                    batchSize: 1,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('status').innerText = `Text Gen Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`;
                        }
                    }
                });
                await textGenModel.save('localstorage://vynix-textgen-model');

                modelsLoaded = true;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('status').innerText = 'Vynix AI is ready!';
                document.getElementById('status').classList.remove('loading');
            } catch (error) {
                console.error('Training error:', error);
                document.getElementById('status').innerText = 'Error training models. Please refresh or check console.';
                document.getElementById('status').classList.remove('loading');
            }
        }

        // Load models
        async function loadModels(dataset) {
            try {
                document.getElementById('status').innerText = 'Loading models...';
                document.getElementById('status').classList.add('loading');
                qaModel = await tf.loadLayersModel('localstorage://vynix-qa-model');
                textGenModel = await tf.loadLayersModel('localstorage://vynix-textgen-model');
                modelsLoaded = true;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('status').innerText = 'Vynix AI is ready!';
                document.getElementById('status').classList.remove('loading');
            } catch (error) {
                console.log('No saved models, training new ones...', error);
                document.getElementById('status').innerText = 'No saved models, training new ones...';
                await trainModels(dataset);
            }
        }

        // Generate text
        async function generateText(input, maxTokens = 10) {
            try {
                let currentInput = input.slice(0, maxGenLength);
                let generated = '';
                for (let i = 0; i < maxTokens; i++) {
                    const inputTensor = preprocessTextGen(currentInput);
                    const prediction = textGenModel.predict(inputTensor);
                    const nextCharIndex = prediction.argMax(-1).dataSync()[0];
                    if (nextCharIndex === 0) break;
                    const nextChar = charVocab[nextCharIndex - 1];
                    generated += nextChar;
                    currentInput = (currentInput + nextChar).slice(1);
                }
                return generated.trim();
            } catch (error) {
                console.error('Text generation error:', error);
                return '';
            }
        }

        // Keyword-based fallback for unseen questions
        function keywordFallback(input) {
            const keywords = input.toLowerCase().split(/\s+/);
            if (keywords.includes('capital')) return 'Try asking about the capital of a country I know, like France or Japan!';
            if (keywords.includes('who')) return 'Try asking about someone famous, like Shakespeare or da Vinci!';
            if (keywords.includes('where')) return 'Try asking about a famous place, like the Great Wall or Machu Picchu!';
            return 'Try a question like "What is the capital of France?" or type a phrase to continue!';
        }

        // Format timestamp (SAST)
        function getTimestamp() {
            const now = new Date();
            const hours = now.getHours() % 12 || 12;
            const minutes = now.getMinutes().toString().padStart(2, '0');
            const ampm = now.getHours() >= 12 ? 'PM' : 'AM';
            return `${hours}:${minutes} ${ampm}`;
        }

        // Send user message and get AI response
        async function sendMessage() {
            if (!modelsLoaded) {
                document.getElementById('status').innerText = 'Please wait, Vynix AI is loading...';
                document.getElementById('status').classList.add('loading');
                return;
            }

            const userInput = document.getElementById('userInput').value.trim();
            if (!userInput) {
                document.getElementById('status').innerText = 'Please enter a message.';
                document.getElementById('status').classList.remove('loading');
                return;
            }

            const userMessage = { role: 'user', content: userInput, timestamp: getTimestamp() };
            chatHistory.push(userMessage);
            await saveMessageToFirebase(userMessage);
            updateChatBox();
            document.getElementById('status').innerText = 'Vynix AI is thinking...';
            document.getElementById('status').classList.add('loading');

            try {
                const dataset = await fetchDataset();
                const vocab = await getVocab(dataset);
                let response;
                if (userInput.toLowerCase().match(/\b(what|where|who)\b/)) {
                    const inputTensor = preprocessQA(userInput, vocab);
                    const prediction = qaModel.predict(inputTensor);
                    const probabilities = prediction.dataSync();
                    const answerIndex = prediction.argMax(-1).dataSync()[0];
                    const confidence = probabilities[answerIndex];

                    if (confidence > confidenceThreshold) {
                        response = `Vynix AI: ${dataset.qa[answerIndex]?.answer || 'I donâ€™t know that one!'}`;
                    } else {
                        response = `Vynix AI: Sorry, I'm not sure about that. ${keywordFallback(userInput)}`;
                    }
                } else {
                    const generated = await generateText(userInput);
                    response = `Vynix AI: ${generated || 'Let me think... Try a question!'}`;
                }

                const aiMessage = { role: 'ai', content: response, timestamp: getTimestamp() };
                chatHistory.push(aiMessage);
                await saveMessageToFirebase(aiMessage);
                updateChatBox();
                document.getElementById('status').innerText = 'Ready.';
                document.getElementById('status').classList.remove('loading');
                document.getElementById('userInput').value = '';
            } catch (error) {
                console.error('Inference error:', error);
                document.getElementById('status').innerText = 'Error processing request. Please try again.';
                document.getElementById('status').classList.remove('loading');
                const errorMessage = { role: 'ai', content: 'Vynix AI: Sorry, something went wrong. Try again!', timestamp: getTimestamp() };
                chatHistory.push(errorMessage);
                await saveMessageToFirebase(errorMessage);
                updateChatBox();
            }
        }

        // Update chat box UI
        function updateChatBox() {
            const chatBox = document.getElementById('chatBox');
            chatBox.innerHTML = '';
            chatHistory.forEach(msg => {
                const div = document.createElement('div');
                div.className = `message ${msg.role === 'user' ? 'user-message' : 'ai-message'}`;
                div.innerHTML = `${msg.role === 'user' ? 'You' : 'Vynix AI'}: ${msg.content}<span class="timestamp">${msg.timestamp}</span>`;
                chatBox.appendChild(div);
            });
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        // Initialize
        async function initialize() {
            try {
                // Check WebGL support
                document.getElementById('status').innerText = 'Checking WebGL support...';
                document.getElementById('status').classList.add('loading');
                if (!tf.getBackend() || tf.getBackend() !== 'webgl') {
                    await tf.setBackend('webgl');
                    if (!tf.getBackend()) {
                        console.warn('WebGL not supported, falling back to CPU');
                        await tf.setBackend('cpu');
                    }
                }

                // Check localStorage
                if (!window.localStorage) {
                    throw new Error('localStorage not available. Please use HTTPS or localhost.');
                }

                // Load chat history
                await loadChatHistory();

                // Fetch dataset and initialize models
                document.getElementById('status').innerText = 'TensorFlow.js loaded, loading models...';
                await tf.ready();
                const dataset = await fetchDataset();
                await loadModels(dataset);
            } catch (error) {
                console.error('Initialization error:', error);
                document.getElementById('status').innerText = 'Error initializing Vynix AI. Please refresh or check console.';
                document.getElementById('status').classList.remove('loading');
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            document.getElementById('userInput').addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && modelsLoaded) sendMessage();
            });
        });
    </script>
</body>
</html>
