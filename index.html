<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vynix AI Chatbot</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }

        .container {
            text-align: center;
            padding: 20px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            width: 90%;
            max-width: 600px;
        }

        .chat-box {
            height: 300px;
            overflow-y: auto;
            border: 1px solid #ccc;
            border-radius: 4px;
            padding: 10px;
            margin-bottom: 10px;
            background-color: #f9f9f9;
        }

        .input-container {
            display: flex;
            gap: 10px;
        }

        input {
            flex: 1;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
        }

        button {
            padding: 10px 20px;
            background: linear-gradient(45deg, #007bff, #00d4ff);
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }

        button:hover:not(:disabled) {
            background: linear-gradient(45deg, #0056b3, #0096cc);
        }

        #status {
            font-style: italic;
            color: #555;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Vynix AI - Powered by BanterBox</h1>
        <div class="chat-box" id="chatBox"></div>
        <div class="input-container">
            <input type="text" id="userInput" placeholder="Ask Vynix AI something..." />
            <button id="sendButton" onclick="sendMessage()" disabled>Send</button>
        </div>
        <p id="status">Checking environment...</p>
    </div>
    <script>
        // Lazy load TensorFlow.js
        const tfScript = document.createElement('script');
        tfScript.src = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js';
        tfScript.onload = initialize;
        tfScript.onerror = () => {
            document.getElementById('status').innerText = 'Error: Failed to load TensorFlow.js. Please refresh.';
            console.error('Failed to load TensorFlow.js');
        };
        document.head.appendChild(tfScript);

        // Global variables
        let qaModel, textGenModel, chatHistory = [], modelsLoaded = false;

        // Custom dataset
        const customDataset = {
            qa: [
                { question: "What is the capital of France?", answer: "Paris" },
                { question: "Who wrote Romeo and Juliet?", answer: "William Shakespeare" },
                { question: "What is the largest planet?", answer: "Jupiter" },
                { question: "Where is the Great Wall?", answer: "China" },
                { question: "What is 2 + 2?", answer: "4" },
                { question: "Who painted the Mona Lisa?", answer: "Leonardo da Vinci" },
                { question: "What is the chemical symbol for water?", answer: "H2O" },
                { question: "What is the tallest mammal?", answer: "Blue Whale" },
                { question: "Where is Machu Picchu?", answer: "Peru" },
                { question: "What is the currency of Japan?", answer: "Yen" }
            ],
            textGen: [
                "The sun sets slowly behind the mountain.",
                "A curious cat explored the garden.",
                "Let's meet at the park tomorrow!",
                "Stars twinkled brightly in the night sky.",
                "The old house creaked in the wind.",
                "I found a shiny coin on the path.",
                "The river flowed gently through the valley.",
                "A bird sang a sweet melody.",
                "We laughed and shared stories by the fire.",
                "The moon glowed softly above the trees."
            ]
        };

        // Vocabulary for Q&A
        const vocab = [...new Set(
            customDataset.qa.flatMap(item => item.question.toLowerCase().split(/\s+/))
                .concat(customDataset.qa.flatMap(item => item.answer.toLowerCase().split(/\s+/)))
        )];
        const charVocab = 'abcdefghijklmnopqrstuvwxyz .!?';
        const maxLength = 10; // Max input length for Q&A
        const maxGenLength = 20; // Max input length for text generation
        const confidenceThreshold = 0.7;

        // Preprocess Q&A input
        function preprocessQA(text) {
            const tokens = text.toLowerCase().split(/\s+/).filter(word => vocab.includes(word));
            const sequence = tokens.map(word => vocab.indexOf(word) + 1).slice(0, maxLength);
            while (sequence.length < maxLength) sequence.push(0);
            return tf.tensor2d([sequence], [1, maxLength], 'int32');
        }

        // Preprocess text generation input
        function preprocessTextGen(text) {
            const chars = text.toLowerCase().split('');
            const sequence = chars.map(c => charVocab.indexOf(c) + 1).slice(0, maxGenLength);
            while (sequence.length < maxGenLength) sequence.push(0);
            return tf.tensor2d([sequence], [1, maxGenLength], 'int32');
        }

        // Create Q&A model (ultra-small)
        function createQAModel(vocabSize) {
            const model = tf.sequential();
            model.add(tf.layers.embedding({ inputDim: vocabSize, outputDim: 1, inputLength: maxLength }));
            model.add(tf.layers.lstm({ units: 2 }));
            model.add(tf.layers.dense({ units: customDataset.qa.length, activation: 'softmax' }));
            model.compile({ optimizer: 'adam', loss: 'sparseCategoricalCrossentropy', metrics: ['accuracy'] });
            return model;
        }

        // Create text generation model (ultra-small)
        function createTextGenModel(charVocabSize) {
            const model = tf.sequential();
            model.add(tf.layers.embedding({ inputDim: charVocabSize, outputDim: 1, inputLength: maxGenLength }));
            model.add(tf.layers.lstm({ units: 4 }));
            model.add(tf.layers.dense({ units: charVocabSize, activation: 'softmax' }));
            model.compile({ optimizer: 'adam', loss: 'sparseCategoricalCrossentropy', metrics: ['accuracy'] });
            return model;
        }

        // Train models
        async function trainModels() {
            try {
                // Check localStorage availability
                if (!window.localStorage) {
                    throw new Error('localStorage is not available');
                }

                // Train Q&A model
                document.getElementById('status').innerText = 'Training Q&A model...';
                qaModel = createQAModel(vocab.length + 1);
                const qaInputs = tf.concat(customDataset.qa.map(item => preprocessQA(item.question)));
                const qaOutputs = tf.tensor1d(customDataset.qa.map((_, i) => i));
                await qaModel.fit(qaInputs, qaOutputs, {
                    epochs: 5, // Minimal epochs
                    batchSize: 1,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('status').innerText = `Q&A Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`;
                        }
                    }
                });
                await qaModel.save('localstorage://vynix-qa-model');

                // Train text generation model
                document.getElementById('status').innerText = 'Training text generation model...';
                textGenModel = createTextGenModel(charVocab.length + 1);
                const textInputs = tf.concat(customDataset.textGen.map(text => preprocessTextGen(text)));
                const textOutputs = tf.tensor1d(
                    customDataset.textGen.map(text => {
                        const chars = text.toLowerCase().split('').slice(1).concat(' ');
                        return chars.map(c => charVocab.indexOf(c) + 1)[0] || 0;
                    })
                );
                await textGenModel.fit(textInputs, textOutputs, {
                    epochs: 5, // Minimal epochs
                    batchSize: 1,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('status').innerText = `Text Gen Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`;
                        }
                    }
                });
                await textGenModel.save('localstorage://vynix-textgen-model');

                modelsLoaded = true;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('status').innerText = 'Models trained and ready!';
            } catch (error) {
                console.error('Training error:', error);
                document.getElementById('status').innerText = 'Error training models. Please refresh or check console.';
            }
        }

        // Load models
        async function loadModels() {
            try {
                document.getElementById('status').innerText = 'Loading models...';
                qaModel = await tf.loadLayersModel('localstorage://vynix-qa-model');
                textGenModel = await tf.loadLayersModel('localstorage://vynix-textgen-model');
                modelsLoaded = true;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('status').innerText = 'Models loaded and ready!';
            } catch (error) {
                console.log('No saved models, training new ones...', error);
                document.getElementById('status').innerText = 'No saved models, training new ones...';
                await trainModels();
            }
        }

        // Generate text
        async function generateText(input, maxTokens = 10) {
            try {
                let currentInput = input.slice(0, maxGenLength);
                let generated = '';
                for (let i = 0; i < maxTokens; i++) {
                    const inputTensor = preprocessTextGen(currentInput);
                    const prediction = textGenModel.predict(inputTensor);
                    const nextCharIndex = prediction.argMax(-1).dataSync()[0];
                    if (nextCharIndex === 0) break;
                    const nextChar = charVocab[nextCharIndex - 1];
                    generated += nextChar;
                    currentInput = (currentInput + nextChar).slice(1);
                }
                return generated.trim();
            } catch (error) {
                console.error('Text generation error:', error);
                return '';
            }
        }

        // Keyword-based fallback for unseen questions
        function keywordFallback(input) {
            const keywords = input.toLowerCase().split(/\s+/);
            if (keywords.includes('capital')) return 'Try asking about the capital of a country I know, like France or Japan!';
            if (keywords.includes('who')) return 'Try asking about someone famous, like Shakespeare or da Vinci!';
            if (keywords.includes('where')) return 'Try asking about a famous place, like the Great Wall or Machu Picchu!';
            return 'Try a question like "What is the capital of France?" or type a phrase to continue!';
        }

        // Send user message and get AI response
        async function sendMessage() {
            if (!modelsLoaded) {
                document.getElementById('status').innerText = 'Please wait, models are loading...';
                return;
            }

            const userInput = document.getElementById('userInput').value.trim();
            if (!userInput) {
                document.getElementById('status').innerText = 'Please enter a message.';
                return;
            }

            chatHistory.push({ role: 'user', content: userInput });
            updateChatBox();
            document.getElementById('status').innerText = 'Vynix AI is thinking...';

            try {
                let response;
                if (userInput.toLowerCase().match(/\b(what|where|who)\b/)) {
                    const inputTensor = preprocessQA(userInput);
                    const prediction = qaModel.predict(inputTensor);
                    const probabilities = prediction.dataSync();
                    const answerIndex = prediction.argMax(-1).dataSync()[0];
                    const confidence = probabilities[answerIndex];

                    if (confidence > confidenceThreshold) {
                        response = `Vynix AI: ${customDataset.qa[answerIndex]?.answer || 'I don’t know that one!'}`;
                    } else {
                        response = `Vynix AI: Sorry, I'm not sure about that. ${keywordFallback(userInput)}`;
                    }
                } else {
                    const generated = await generateText(userInput);
                    response = `Vynix AI: ${generated || 'Let me think... Try a question!'}`;
                }

                chatHistory.push({ role: 'ai', content: response });
                updateChatBox();
                document.getElementById('status').innerText = 'Ready.';
                document.getElementById('userInput').value = '';
            } catch (error) {
                console.error('Inference error:', error);
                document.getElementById('status').innerText = 'Error processing request. Please try again.';
                chatHistory.push({ role: 'ai', content: 'Vynix AI: Sorry, something went wrong. Try again!' });
                updateChatBox();
            }
        }

        // Update chat box UI
        function updateChatBox() {
            const chatBox = document.getElementById('chatBox');
            chatBox.innerHTML = '';
            chatHistory.forEach(msg => {
                const div = document.createElement('div');
                div.style.textAlign = msg.role === 'user' ? 'right' : 'left';
                div.style.margin = '5px';
                div.style.padding = '10px';
                div.style.backgroundColor = msg.role === 'user' ? '#007bff' : '#e0e0e0';
                div.style.color = msg.role === 'user' ? 'white' : 'black';
                div.style.borderRadius = '8px';
                div.innerText = `${msg.role === 'user' ? 'You' : 'Vynix AI'}: ${msg.content}`;
                chatBox.appendChild(div);
            });
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        // Initialize
        async function initialize() {
            try {
                // Check WebGL support
                document.getElementById('status').innerText = 'Checking WebGL support...';
                if (!tf.getBackend() || tf.getBackend() !== 'webgl') {
                    await tf.setBackend('webgl');
                    if (!tf.getBackend()) {
                        throw new Error('WebGL not supported');
                    }
                }

                // Check localStorage
                if (!window.localStorage) {
                    throw new Error('localStorage not available');
                }

                document.getElementById('status').innerText = 'TensorFlow.js loaded, loading models...';
                await tf.ready();
                await loadModels();
            } catch (error) {
                console.error('Initialization error:', error);
                document.getElementById('status').innerText = 'Error initializing Vynix AI. Please refresh or check console.';
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            document.getElementById('userInput').addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && modelsLoaded) sendMessage();
            });
        });
    </script>
</body>
</html>
