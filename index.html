<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vynix AI Chatbot</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            min-height: 100vh;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: auto;
            background-image: radial-gradient(circle, rgba(255, 255, 255, 0.1) 1px, transparent 1px);
            background-size: 20px 20px;
        }

        .container {
            text-align: center;
            padding: 15px;
            background: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            width: 95%;
            max-width: 700px;
            backdrop-filter: blur(5px);
        }

        h1 {
            font-size: 1.6em;
            margin: 0 0 15px;
            color: #00d4ff;
            text-shadow: 0 0 10px rgba(0, 212, 255, 0.5);
        }

        .chat-box {
            height: 400px;
            overflow-y: auto;
            padding: 10px;
            margin-bottom: 10px;
            background: rgba(0, 0, 0, 0.2);
        }

        .message {
            display: flex;
            flex-direction: column;
            margin: 8px 10px;
            padding: 8px 12px;
            border-radius: 12px;
            max-width: 70%;
            word-wrap: break-word;
            animation: fadeIn 0.3s ease-in;
            position: relative;
        }

        .user-message {
            background: linear-gradient(45deg, #007bff, #00d4ff);
            color: white;
            margin-left: auto;
            border-top-right-radius: 2px;
        }

        .ai-message {
            background: rgba(255, 255, 255, 0.1);
            color: #e0e0e0;
            margin-right: auto;
            border-top-left-radius: 2px;
        }

        .timestamp {
            font-size: 0.7em;
            color: rgba(255, 255, 255, 0.6);
            align-self: flex-end;
            margin-top: 4px;
        }

        .input-container {
            display: flex;
            gap: 8px;
            background: rgba(255, 255, 255, 0.1);
            padding: 8px;
            border-radius: 20px;
        }

        input {
            flex: 1;
            padding: 10px;
            border: none;
            border-radius: 20px;
            background: transparent;
            color: #e0e0e0;
            font-size: 1em;
            outline: none;
        }

        input::placeholder {
            color: rgba(255, 255, 255, 0.5);
        }

        button {
            padding: 10px;
            background: transparent;
            border: none;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .send-icon {
            width: 24px;
            height: 24px;
            background: url('data:image/svg+xml;utf8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="%23e0e0e0"><path d="M2.01 21L23 12 2.01 3 2 10l15 2-15 2z"/></svg>') no-repeat center;
            background-size: contain;
        }

        #status {
            font-size: 0.8em;
            color: rgba(255, 255, 255, 0.7);
            margin-top: 8px;
        }

        .loading::after {
            content: '';
            display: inline-block;
            width: 14px;
            height: 14px;
            border: 2px solid #00d4ff;
            border-radius: 50%;
            border-top-color: transparent;
            animation: spin 1s linear infinite;
            margin-left: 8px;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @media (max-width: 600px) {
            .container {
                width: 98%;
                padding: 10px;
            }

            h1 {
                font-size: 1.4em;
            }

            .chat-box {
                height: 300px;
            }

            .message {
                max-width: 80%;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Vynix AI - Powered by BanterBox</h1>
        <div class="chat-box" id="chatBox"></div>
        <div class="input-container">
            <input type="text" id="userInput" placeholder="Ask Vynix AI something..." />
            <button id="sendButton" onclick="sendMessage()" disabled><span class="send-icon"></span></button>
        </div>
        <p id="status" class="loading">Checking environment...</p>
    </div>
    <script>
        // Lazy load TensorFlow.js
        const tfScript = document.createElement('script');
        tfScript.src = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.21.0/dist/tf.min.js';
        tfScript.onload = initialize;
        tfScript.onerror = () => {
            document.getElementById('status').innerText = 'Error: Failed to load TensorFlow.js. Please refresh.';
            console.error('Failed to load TensorFlow.js');
        };
        document.head.appendChild(tfScript);

        // Global variables
        let qaModel, textGenModel, chatHistory = [], modelsLoaded = false;

        // Custom dataset
        const customDataset = {
            qa: [
                { question: "What is the capital of France?", answer: "Paris" },
                { question: "Who wrote Romeo and Juliet?", answer: "William Shakespeare" },
                { question: "What is the largest planet?", answer: "Jupiter" },
                { question: "Where is the Great Wall?", answer: "China" },
                { question: "What is 2 + 2?", answer: "4" },
                { question: "Who painted the Mona Lisa?", answer: "Leonardo da Vinci" },
                { question: "What is the chemical symbol for water?", answer: "H2O" },
                { question: "What is the tallest mammal?", answer: "Blue Whale" },
                { question: "Where is Machu Picchu?", answer: "Peru" },
                { question: "What is the currency of Japan?", answer: "Yen" }
            ],
            textGen: [
                "The sun sets slowly behind the mountain.",
                "A curious cat explored the garden.",
                "Let's meet at the park tomorrow!",
                "Stars twinkled brightly in the night sky.",
                "The old house creaked in the wind.",
                "I found a shiny coin on the path.",
                "The river flowed gently through the valley.",
                "A bird sang a sweet melody.",
                "We laughed and shared stories by the fire.",
                "The moon glowed softly above the trees."
            ]
        };

        // Vocabulary for Q&A
        const vocab = [...new Set(
            customDataset.qa.flatMap(item => item.question.toLowerCase().split(/\s+/))
                .concat(customDataset.qa.flatMap(item => item.answer.toLowerCase().split(/\s+/)))
        )];
        const charVocab = 'abcdefghijklmnopqrstuvwxyz .!?';
        const maxLength = 10; // Max input length for Q&A
        const maxGenLength = 20; // Max input length for text generation
        const confidenceThreshold = 0.7;

        // Preprocess Q&A input
        function preprocessQA(text) {
            const tokens = text.toLowerCase().split(/\s+/).filter(word => vocab.includes(word));
            const sequence = tokens.map(word => vocab.indexOf(word) + 1).slice(0, maxLength);
            while (sequence.length < maxLength) sequence.push(0);
            return tf.tensor2d([sequence], [1, maxLength], 'int32');
        }

        // Preprocess text generation input
        function preprocessTextGen(text) {
            const chars = text.toLowerCase().split('');
            const sequence = chars.map(c => charVocab.indexOf(c) + 1).slice(0, maxGenLength);
            while (sequence.length < maxGenLength) sequence.push(0);
            return tf.tensor2d([sequence], [1, maxGenLength], 'int32');
        }

        // Create Q&A model (ultra-small)
        function createQAModel(vocabSize) {
            const model = tf.sequential();
            model.add(tf.layers.embedding({ inputDim: vocabSize, outputDim: 1, inputLength: maxLength }));
            model.add(tf.layers.lstm({ units: 2 }));
            model.add(tf.layers.dense({ units: customDataset.qa.length, activation: 'softmax' }));
            model.compile({ optimizer: 'adam', loss: 'sparseCategoricalCrossentropy', metrics: ['accuracy'] });
            return model;
        }

        // Create text generation model (ultra-small)
        function createTextGenModel(charVocabSize) {
            const model = tf.sequential();
            model.add(tf.layers.embedding({ inputDim: charVocabSize, outputDim: 1, inputLength: maxGenLength }));
            model.add(tf.layers.lstm({ units: 3 }));
            model.add(tf.layers.dense({ units: charVocabSize, activation: 'softmax' }));
            model.compile({ optimizer: 'adam', loss: 'sparseCategoricalCrossentropy', metrics: ['accuracy'] });
            return model;
        }

        // Train models
        async function trainModels() {
            try {
                // Check localStorage
                if (!window.localStorage) {
                    throw new Error('localStorage is not available');
                }

                // Train Q&A model
                document.getElementById('status').innerText = 'Training Q&A model...';
                document.getElementById('status').classList.add('loading');
                qaModel = createQAModel(vocab.length + 1);
                const qaInputs = tf.concat(customDataset.qa.map(item => preprocessQA(item.question)));
                const qaOutputs = tf.tensor1d(customDataset.qa.map((_, i) => i));
                await qaModel.fit(qaInputs, qaOutputs, {
                    epochs: 5,
                    batchSize: 1,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('status').innerText = `Q&A Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`;
                        }
                    }
                });
                await qaModel.save('localstorage://vynix-qa-model');

                // Train text generation model
                document.getElementById('status').innerText = 'Training text generation model...';
                textGenModel = createTextGenModel(charVocab.length + 1);
                const textInputs = tf.concat(customDataset.textGen.map(text => preprocessTextGen(text)));
                const textOutputs = tf.tensor1d(
                    customDataset.textGen.map(text => {
                        const chars = text.toLowerCase().split('').slice(1).concat(' ');
                        return chars.map(c => charVocab.indexOf(c) + 1)[0] || 0;
                    })
                );
                await textGenModel.fit(textInputs, textOutputs, {
                    epochs: 5,
                    batchSize: 1,
                    shuffle: true,
                    callbacks: {
                        onEpochEnd: (epoch, logs) => {
                            document.getElementById('status').innerText = `Text Gen Epoch ${epoch + 1}: Loss = ${logs.loss.toFixed(4)}`;
                        }
                    }
                });
                await textGenModel.save('localstorage://vynix-textgen-model');

                modelsLoaded = true;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('status').innerText = 'Vynix AI is ready!';
                document.getElementById('status').classList.remove('loading');
            } catch (error) {
                console.error('Training error:', error);
                document.getElementById('status').innerText = 'Error training models. Please refresh or check console.';
                document.getElementById('status').classList.remove('loading');
            }
        }

        // Load models
        async function loadModels() {
            try {
                document.getElementById('status').innerText = 'Loading models...';
                document.getElementById('status').classList.add('loading');
                qaModel = await tf.loadLayersModel('localstorage://vynix-qa-model');
                textGenModel = await tf.loadLayersModel('localstorage://vynix-textgen-model');
                modelsLoaded = true;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('status').innerText = 'Vynix AI is ready!';
                document.getElementById('status').classList.remove('loading');
            } catch (error) {
                console.log('No saved models, training new ones...', error);
                document.getElementById('status').innerText = 'No saved models, training new ones...';
                await trainModels();
            }
        }

        // Generate text
        async function generateText(input, maxTokens = 10) {
            try {
                let currentInput = input.slice(0, maxGenLength);
                let generated = '';
                for (let i = 0; i < maxTokens; i++) {
                    const inputTensor = preprocessTextGen(currentInput);
                    const prediction = textGenModel.predict(inputTensor);
                    const nextCharIndex = prediction.argMax(-1).dataSync()[0];
                    if (nextCharIndex === 0) break;
                    const nextChar = charVocab[nextCharIndex - 1];
                    generated += nextChar;
                    currentInput = (currentInput + nextChar).slice(1);
                }
                return generated.trim();
            } catch (error) {
                console.error('Text generation error:', error);
                return '';
            }
        }

        // Keyword-based fallback for unseen questions
        function keywordFallback(input) {
            const keywords = input.toLowerCase().split(/\s+/);
            if (keywords.includes('capital')) return 'Try asking about the capital of a country I know, like France or Japan!';
            if (keywords.includes('who')) return 'Try asking about someone famous, like Shakespeare or da Vinci!';
            if (keywords.includes('where')) return 'Try asking about a famous place, like the Great Wall or Machu Picchu!';
            return 'Try a question like "What is the capital of France?" or type a phrase to continue!';
        }

        // Format timestamp
        function getTimestamp() {
            const now = new Date();
            const hours = now.getHours() % 12 || 12;
            const minutes = now.getMinutes().toString().padStart(2, '0');
            const ampm = now.getHours() >= 12 ? 'PM' : 'AM';
            return `${hours}:${minutes} ${ampm}`;
        }

        // Send user message and get AI response
        async function sendMessage() {
            if (!modelsLoaded) {
                document.getElementById('status').innerText = 'Please wait, Vynix AI is loading...';
                document.getElementById('status').classList.add('loading');
                return;
            }

            const userInput = document.getElementById('userInput').value.trim();
            if (!userInput) {
                document.getElementById('status').innerText = 'Please enter a message.';
                document.getElementById('status').classList.remove('loading');
                return;
            }

            chatHistory.push({ role: 'user', content: userInput, timestamp: getTimestamp() });
            updateChatBox();
            document.getElementById('status').innerText = 'Vynix AI is thinking...';
            document.getElementById('status').classList.add('loading');

            try {
                let response;
                if (userInput.toLowerCase().match(/\b(what|where|who)\b/)) {
                    const inputTensor = preprocessQA(userInput);
                    const prediction = qaModel.predict(inputTensor);
                    const probabilities = prediction.dataSync();
                    const answerIndex = prediction.argMax(-1).dataSync()[0];
                    const confidence = probabilities[answerIndex];

                    if (confidence > confidenceThreshold) {
                        response = `Vynix AI: ${customDataset.qa[answerIndex]?.answer || 'I donâ€™t know that one!'}`;
                    } else {
                        response = `Vynix AI: Sorry, I'm not sure about that. ${keywordFallback(userInput)}`;
                    }
                } else {
                    const generated = await generateText(userInput);
                    response = `Vynix AI: ${generated || 'Let me think... Try a question!'}`;
                }

                chatHistory.push({ role: 'ai', content: response, timestamp: getTimestamp() });
                updateChatBox();
                document.getElementById('status').innerText = 'Ready.';
                document.getElementById('status').classList.remove('loading');
                document.getElementById('userInput').value = '';
            } catch (error) {
                console.error('Inference error:', error);
                document.getElementById('status').innerText = 'Error processing request. Please try again.';
                document.getElementById('status').classList.remove('loading');
                chatHistory.push({ role: 'ai', content: 'Vynix AI: Sorry, something went wrong. Try again!', timestamp: getTimestamp() });
                updateChatBox();
            }
        }

        // Update chat box UI
        function updateChatBox() {
            const chatBox = document.getElementById('chatBox');
            chatBox.innerHTML = '';
            chatHistory.forEach(msg => {
                const div = document.createElement('div');
                div.className = `message ${msg.role === 'user' ? 'user-message' : 'ai-message'}`;
                div.innerHTML = `${msg.role === 'user' ? 'You' : 'Vynix AI'}: ${msg.content}<span class="timestamp">${msg.timestamp}</span>`;
                chatBox.appendChild(div);
            });
            chatBox.scrollTop = chatBox.scrollHeight;
        }

        // Initialize
        async function initialize() {
            try {
                // Check WebGL support
                document.getElementById('status').innerText = 'Checking WebGL support...';
                document.getElementById('status').classList.add('loading');
                if (!tf.getBackend() || tf.getBackend() !== 'webgl') {
                    await tf.setBackend('webgl');
                    if (!tf.getBackend()) {
                        console.warn('WebGL not supported, falling back to CPU');
                        await tf.setBackend('cpu');
                    }
                }

                // Check localStorage
                if (!window.localStorage) {
                    throw new Error('localStorage not available. Please use HTTPS or localhost.');
                }

                document.getElementById('status').innerText = 'TensorFlow.js loaded, loading models...';
                await tf.ready();
                await loadModels();
            } catch (error) {
                console.error('Initialization error:', error);
                document.getElementById('status').innerText = 'Error initializing Vynix AI. Please refresh or check console.';
                document.getElementById('status').classList.remove('loading');
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            document.getElementById('userInput').addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && modelsLoaded) sendMessage();
            });
        });
    </script>
</body>
</html>
