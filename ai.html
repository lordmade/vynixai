<!DOCTYPE html>
<html lang="en" dir="ltr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>Vynix AI - BBM Edition</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://www.gstatic.com/firebasejs/10.14.1/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/10.14.1/firebase-auth.js"></script>
  <script src="https://www.gstatic.com/firebasejs/10.14.1/firebase-database.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700;900&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg: #f8f8f8;
      --card-bg: #ffffff;
      --text-primary: #000000;
      --text-secondary: #666666;
      --border: #e0e0e0;
      --accent: #d40000;
      --bbm-red: #d40000;
      --header-bg: #ffffff;
      --user-msg-bg: #e6f3ff;
      --ai-msg-bg: #ffffff;
      --shadow-sm: 0 2px 4px rgba(0, 0, 0, 0.1);
      --shadow-md: 0 4px 12px rgba(0, 0, 0, 0.1);
      --glow: 0 0 10px rgba(212, 0, 0, 0.3);
    }
    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
      background: var(--bg);
      color: var(--text-primary);
      margin: 0;
      padding: 0;
      overflow-x: hidden;
      line-height: 1.6;
      transition: background-color 0.3s ease, color 0.3s ease;
      -webkit-touch-callout: none;
      -webkit-user-select: none;
      -khtml-user-select: none;
      -moz-user-select: none;
      -ms-user-select: none;
      user-select: none;
      -webkit-tap-highlight-color: transparent;
    }
    .main-content {
      padding: 20px;
      min-height: calc(100vh - 140px);
      transition: padding 0.3s ease;
    }
    #chat-messages {
      padding-bottom: 120px;
      display: flex;
      flex-direction: column;
      gap: 16px;
    }
    .message {
      max-width: 70%;
      padding: 16px;
      border-radius: 28px;
      overflow: hidden;
      box-shadow: var(--shadow-md);
      position: relative;
      cursor: pointer;
      transition: all 0.3s ease;
      word-wrap: break-word;
      animation: slideIn 0.3s ease-out;
      -webkit-touch-callout: none;
      -webkit-user-select: none;
      -khtml-user-select: none;
      -moz-user-select: none;
      -ms-user-select: none;
      user-select: none;
    }
    .message::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      right: 0;
      height: 4px;
      background: var(--bbm-red);
      transform: scaleX(0);
      transition: transform 0.3s ease;
    }
    .message:hover::before {
      transform: scaleX(1);
    }
    .message.user {
      background: var(--user-msg-bg);
      color: var(--text-primary);
      align-self: flex-end;
      border-bottom-right-radius: 4px;
    }
    .message.ai {
      background: var(--ai-msg-bg);
      color: var(--text-primary);
      align-self: flex-start;
      border-bottom-left-radius: 4px;
    }
    .message.processing {
      background: var(--ai-msg-bg);
      color: var(--text-primary);
      font-style: italic;
      opacity: 0.7;
    }
    .message img {
      max-width: 100%;
      border-radius: 20px;
      margin-top: 10px;
      box-shadow: var(--shadow-md);
    }
    .typing-indicator {
      color: var(--bbm-red);
      font-style: italic;
      display: inline-flex;
      gap: 0.25rem;
      align-items: center;
    }
    .typing-dot {
      width: 0.5rem;
      height: 0.5rem;
      background: var(--bbm-red);
      border-radius: 50%;
      animation: typing 1.2s infinite;
    }
    .typing-dot:nth-child(2) { animation-delay: 0.2s; }
    .typing-dot:nth-child(3) { animation-delay: 0.4s; }
    @keyframes typing {
      0%, 100% { opacity: 0.3; transform: translateY(0); }
      50% { opacity: 1; transform: translateY(-3px); }
    }
    @keyframes slideIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .welcome-container {
      padding-top: 20px;
      text-align: center;
      font-family: 'Orbitron', monospace;
      color: var(--bbm-red);
      font-weight: 900;
      font-size: 20px;
      letter-spacing: 0.5px;
      text-shadow: 0 0 10px rgba(212, 0, 0, 0.3);
    }
    .chat-input-container {
      position: fixed;
      bottom: 0;
      left: 0;
      right: 0;
      background: var(--card-bg);
      border-top: 1px solid var(--border);
      padding: 12px 24px;
      display: flex;
      align-items: center;
      gap: 12px;
      z-index: 10;
      box-shadow: var(--shadow-sm);
      transition: all 0.3s ease;
      margin: 0 20px;
      border-radius: 28px 28px 0 0;
    }
    .input-pill {
      flex: 1;
      display: flex;
      background: var(--card-bg);
      border: 1px solid var(--border);
      border-radius: 28px;
      overflow: hidden;
      box-shadow: var(--shadow-sm);
      transition: border-color 0.3s ease;
    }
    .input-pill input {
      flex: 1;
      background: none;
      border: none;
      outline: none;
      padding: 14px 20px;
      color: var(--text-primary);
      font-size: 16px;
    }
    .send-btn {
      background: var(--bbm-red);
      color: white;
      border: none;
      padding: 14px 20px;
      cursor: pointer;
      font-weight: 700;
      border-radius: 50%;
      width: 44px;
      height: 44px;
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: var(--shadow-sm);
      transition: all 0.3s ease;
    }
    .send-btn:hover {
      background: #b30000;
      box-shadow: var(--glow);
      transform: scale(1.1);
    }
    .send-btn svg {
      font-size: 20px;
    }
    .new-chat-fab {
      position: fixed;
      bottom: 90px;
      background: var(--bbm-red);
      color: white;
      border: none;
      border-radius: 50%;
      width: 56px;
      height: 56px;
      display: flex;
      align-items: center;
      justify-content: center;
      box-shadow: var(--shadow-md);
      cursor: pointer;
      z-index: 100;
      transition: all 0.3s ease;
      font-size: 28px;
      right: 20px;
    }
    .new-chat-fab:hover {
      background: #b30000;
      box-shadow: var(--glow);
      transform: scale(1.1);
    }
    .hidden { display: none; }
    .loading-overlay {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: rgba(248, 248, 248, 0.9);
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      transition: opacity 0.3s ease;
    }
    .loading-overlay.hidden {
      opacity: 0;
      pointer-events: none;
    }
    .loading-text {
      font-family: 'Orbitron', monospace;
      color: var(--bbm-red);
      font-weight: 900;
      font-size: 18px;
      letter-spacing: 0.5px;
      margin-bottom: 20px;
      text-shadow: 0 0 10px rgba(212, 0, 0, 0.3);
    }
    #model-progress {
      width: 200px;
      height: 8px;
      border-radius: 4px;
      background: #e0e0e0;
      overflow: hidden;
    }
    #model-progress::-webkit-progress-bar {
      background: #e0e0e0;
      border-radius: 4px;
    }
    #model-progress::-webkit-progress-value {
      background: var(--bbm-red);
      border-radius: 4px;
    }
    #model-progress::-moz-progress-bar {
      background: var(--bbm-red);
      border-radius: 4px;
    }
    .error {
      background: #fee;
      color: #c33;
      padding: 12px;
      border-radius: 6px;
      margin: 20px 0;
      border-left: 4px solid #c33;
      text-align: center;
    }
    .retrain-notification {
      position: fixed;
      top: 20px;
      right: 20px;
      background: var(--bbm-red);
      color: white;
      padding: 12px 20px;
      border-radius: 20px;
      box-shadow: var(--shadow-md);
      z-index: 100;
      animation: slideIn 0.3s ease-out;
      font-family: 'Orbitron', monospace;
      font-weight: 700;
    }
    .model-status {
      text-align: center;
      padding: 10px;
      font-size: 14px;
      color: var(--text-secondary);
      margin-top: 10px;
    }
    @media (min-width: 1024px) {
      .chat-input-container {
        margin: 0;
        left: 0;
        right: 0;
        border-radius: 0;
      }
      .main-content {
        padding: 20px 20px 120px;
      }
      .new-chat-fab {
        bottom: 90px;
        right: 20px;
      }
    }
  </style>
</head>
<body class="light">
  <!-- Loading Overlay -->
  <div id="loading-overlay" class="loading-overlay">
    <div class="loading-text" id="loading-text">Connecting to Vynix...</div>
    <progress id="model-progress" value="0" max="100"></progress>
    <div class="typing-indicator" style="margin-top: 20px;">
      <span class="typing-dot"></span>
      <span class="typing-dot"></span>
      <span class="typing-dot"></span>
    </div>
    <div id="model-status" class="model-status"></div>
  </div>

  <!-- Retrain Notification -->
  <div id="retrain-notification" class="retrain-notification hidden">
    Vynix just got smarter! ðŸ§ 
  </div>

  <!-- Error Message -->
  <div id="error-message" class="error hidden"></div>

  <main class="main-content">
    <button id="new-conversation-button" class="new-chat-fab hidden" title="New Conversation">
      <span class="material-icons">add</span>
    </button>
    <div class="welcome-container" id="welcome-container">
      <span class="material-icons" style="font-size: 24px; color: var(--bbm-red);">smart_toy</span>
      Hey there, friend! Ready for a chat with Vynix.
    </div>
    <div id="chat-messages"></div>
    <div class="chat-input-container hidden" id="input-container">
      <div class="input-pill">
        <input type="text" id="user-input" placeholder="Type your message... (e.g., 'hello')" required>
      </div>
      <button id="send-button" class="send-btn material-icons">send</button>
    </div>
  </main>
  <script type="module">
    import { initializeApp } from "https://www.gstatic.com/firebasejs/10.14.1/firebase-app.js";
    import { getAuth, onAuthStateChanged, signInAnonymously, signOut } from "https://www.gstatic.com/firebasejs/10.14.1/firebase-auth.js";
    import { getDatabase, ref, onValue } from "https://www.gstatic.com/firebasejs/10.14.1/firebase-database.js";

    const firebaseConfig = {
      apiKey: "AIzaSyBOyZ3As4GTuNvjemvPF_SpsC6m6vqtNhc",
      authDomain: "fire-b-a8878.firebaseapp.com",
      databaseURL: "https://fire-b-a8878.firebaseio.com",
      projectId: "fire-b-a8878",
      storageBucket: "fire-b-a8878.firebasestorage.app",
      messagingSenderId: "658673187627",
      appId: "1:658673187627:web:6e4c29af661785f0afa36e",
      measurementId: "G-V4W97VMSKL"
    };

    const app = initializeApp(firebaseConfig);
    const auth = getAuth(app);
    const db = getDatabase(app);

    const elements = {
      loadingOverlay: document.getElementById('loading-overlay'),
      loadingText: document.getElementById('loading-text'),
      modelProgress: document.getElementById('model-progress'),
      modelStatus: document.getElementById('model-status'),
      errorMessage: document.getElementById('error-message'),
      welcomeContainer: document.getElementById('welcome-container'),
      chatMessages: document.getElementById('chat-messages'),
      userInput: document.getElementById('user-input'),
      inputContainer: document.getElementById('input-container'),
      sendButton: document.getElementById('send-button'),
      newConversationButton: document.getElementById('new-conversation-button'),
      retrainNotification: document.getElementById('retrain-notification')
    };

    let currentUser;
    let trainingData = {};  // For fallback
    let vynixModel = null;  // { model, vocab, uniqueAnswers, modelType, ... }
    let lastModelTimestamp = 0;
    let hasChatted = false;
    let messages = [];

    // Seq2Seq tokens
    const SPECIAL_TOKENS = { PAD: '<PAD>', SOS: '<SOS>', EOS: '<EOS>', UNK: '<UNK>' };
    const STOPWORDS = new Set(['the','a','an','and','or','but','in','on','at','to','for','of','with','is','are','was','were','i','you','he','she','it','we','they','this','that','what','how','why','when','where','my','your','his','her','its','our','their','me','him','us','them','be','have','do','does','did','will','would','can','could','should','may','might','must']);

    function showError(msg) {
      elements.errorMessage.textContent = msg;
      elements.errorMessage.classList.remove('hidden');
      setTimeout(() => elements.errorMessage.classList.add('hidden'), 5000);
    }

    function hideError() {
      elements.errorMessage.classList.add('hidden');
    }

    function updateModelStatus(status) {
      elements.modelStatus.textContent = status;
    }

    function addMessage(content, isUser = false, isTyping = false) {
      const messageDiv = document.createElement('div');
      messageDiv.className = `message ${isUser ? 'user' : 'ai'}${isTyping ? ' processing' : ''}`;
      if (isTyping) {
        messageDiv.innerHTML = '<div class="typing-indicator"><span class="typing-dot"></span><span class="typing-dot"></span><span class="typing-dot"></span></div>';
      } else {
        messageDiv.textContent = content;
      }
      messages.push({ content, isUser });
      elements.chatMessages.appendChild(messageDiv);
      elements.chatMessages.scrollTop = elements.chatMessages.scrollHeight;
      return messageDiv;
    }

    // TF.js Helpers for all models
    function tokenize(text) {
      return text.toLowerCase().split(/\s+/).filter(w => w.length > 1 && !STOPWORDS.has(w));
    }

    function textToVector(text, vocab) {
      const vec = new Array(vocab.length).fill(0);
      tokenize(text).forEach(word => {
        const idx = vocab.indexOf(word);
        if (idx > -1) vec[idx] = 1;
      });
      return vec;
    }

    function encoderSequence(text, wordToIdx, maxLen) {
      const words = tokenize(text);
      let seq = words.map(w => wordToIdx.get(w) || wordToIdx.get(SPECIAL_TOKENS.UNK));
      seq = seq.concat(Array(maxLen - seq.length).fill(wordToIdx.get(SPECIAL_TOKENS.PAD)));
      return seq.slice(0, maxLen);
    }

    // Fallback rule-based reply using training_data
    function generateFallbackReply(userQuery) {
      const loweredQuery = userQuery.toLowerCase().trim();

      // Exact match search
      for (const key in trainingData) {
        const pair = trainingData[key];
        if (pair && pair.q === loweredQuery) {
          return pair.a;
        }
      }

      // Simple fuzzy match
      for (const key in trainingData) {
        const pair = trainingData[key];
        if (pair && (loweredQuery.includes(pair.q) || pair.q.includes(loweredQuery))) {
          return pair.a;
        }
      }

      // Fallback
      return "I'm not sure how to respond to that yet. Am currently still learning ðŸ¤“!";
    }

    // Generate reply using loaded TF model
    async function generateModelReply(userQuery) {
      if (!vynixModel) return generateFallbackReply(userQuery);

      try {
        const { model, modelType } = vynixModel;
        if (modelType === 'classifier') {
          const inputVec = textToVector(userQuery, vynixModel.vocab);
          const inputTensor = tf.tensor2d([inputVec]);
          const pred = model.predict(inputTensor);
          const predIdx = pred.argMax(-1).dataSync()[0];
          const response = vynixModel.uniqueAnswers[predIdx] || generateFallbackReply(userQuery);
          pred.dispose();
          inputTensor.dispose();
          return response;
        } else if (modelType === 'lstm') {
          const wordToIdx = new Map([['<PAD>', 0], ['<UNK>', 1], ...vynixModel.vocab.map((w, i) => [w, i + 2])]);
          const words = tokenize(userQuery);
          let seq = words.map(w => wordToIdx.get(w) || 1);
          seq = seq.concat(Array(vynixModel.maxLen - seq.length).fill(0));
          seq = seq.slice(0, vynixModel.maxLen);
          const inputTensor = tf.tensor2d([seq]);
          const pred = model.predict(inputTensor);
          const predIdx = pred.argMax(-1).dataSync()[0];
          const response = vynixModel.uniqueAnswers[predIdx] || generateFallbackReply(userQuery);
          pred.dispose();
          inputTensor.dispose();
          return response;
        } else if (modelType === 'seq2seq') {
          const generated = await generateSeq2Seq(model, vynixModel.wordToIdx, vynixModel.idxToWord, userQuery, vynixModel.maxLen, vynixModel.vocabSize);
          return generated || generateFallbackReply(userQuery);
        }
      } catch (error) {
        console.error('Prediction error:', error);
        return generateFallbackReply(userQuery);
      }
    }

    // Seq2Seq Generation
    async function generateSeq2Seq(model, wordToIdx, idxToWord, question, maxLen, vocabSize) {
      const inputSeq = tf.tensor2d([encoderSequence(question, wordToIdx, maxLen)]);
      // Extract encoder states (manual forward pass since functional model)
      const encoderEmbeddingLayer = model.layers.find(l => l.name === 'encoder_embedding'); // Assume named layers
      if (!encoderEmbeddingLayer) throw new Error('Model layers not found');
      const encoderEmbedding = encoderEmbeddingLayer.apply(inputSeq);
      const encoderLSTM = model.layers.find(l => l.name === 'encoder_lstm');
      const encoderStates = encoderLSTM.apply(encoderEmbedding);
      const [h, c] = encoderStates; // Assuming returnState gives [h, c]

      let generated = [];
      let inputToken = tf.tensor2d([[wordToIdx.get(SPECIAL_TOKENS.SOS)]]);
      let stop = false;
      for (let t = 0; t < maxLen; t++) {
        const decEmbeddingLayer = model.layers.find(l => l.name === 'decoder_embedding');
        const decEmbedding = decEmbeddingLayer.apply(inputToken);
        const decoderLSTM = model.layers.find(l => l.name === 'decoder_lstm');
        const decOutput = decoderLSTM.apply(decEmbedding, { initialState: [h, c] });
        const denseLayer = model.layers.find(l => l.name === 'dense');
        const prediction = denseLayer.apply(decOutput);
        const predictedId = prediction.argMax(-1).dataSync()[0][0];
        const word = idxToWord.get(predictedId);
        if (word && word !== SPECIAL_TOKENS.PAD) {
          generated.push(word);
        }
        if (predictedId === wordToIdx.get(SPECIAL_TOKENS.EOS)) {
          stop = true;
          break;
        }
        inputToken.dispose();
        inputToken = tf.tensor2d([[predictedId]]);
        prediction.dispose();
        decOutput.dispose();
        decEmbedding.dispose();
      }
      inputSeq.dispose();
      encoderEmbedding.dispose();
      encoderStates.dispose();
      h.dispose();
      c.dispose();
      inputToken.dispose();
      return generated.join(' ');
    }

    async function sendMessage() {
      const userQuery = elements.userInput.value.trim();
      if (!userQuery) return;

      addMessage(userQuery, true);
      elements.userInput.value = '';
      hasChatted = true;
      elements.welcomeContainer.classList.add('hidden');
      elements.newConversationButton.classList.remove('hidden');

      const tempMsg = addMessage('', false, true);
      setTimeout(async () => {
        const reply = await generateModelReply(userQuery);
        tempMsg.textContent = reply;
        tempMsg.classList.remove('processing');
      }, 500 + Math.random() * 500);
    }

    // Load fallback training data
    function loadTrainingData() {
      const trainingRef = ref(db, 'training_data');
      onValue(trainingRef, (snapshot) => {
        trainingData = snapshot.val() || {};
        console.log(`Fallback data loaded: ${Object.keys(trainingData).length} pairs`);
      }, (error) => {
        console.error('Fallback data error:', error);
      });
    }

    // Seq2Seq Model Creator (for loading)
    function createSeq2SeqModel(vocabSize, embedDim = 64, hiddenDim = 128, maxLen, layerNames = true) {
      const encoderInputs = tf.input({shape: [maxLen], name: 'encoder_input'});
      let encoderEmbedding = tf.layers.embedding({
        inputDim: vocabSize,
        outputDim: embedDim,
        inputLength: maxLen,
        name: 'encoder_embedding'
      }).apply(encoderInputs);
      const encoderLSTM = tf.layers.lstm({
        units: hiddenDim,
        returnSequences: false,
        dropout: 0.2,
        name: 'encoder_lstm'
      });
      const encoderOutputs = encoderLSTM.apply(encoderEmbedding);
      const [encoderStatesH, encoderStatesC] = encoderOutputs; // Since returnState not used, adjust if needed

      // For simplicity, use last hidden as states (full rnn returnState in TF.js functional is tricky; approximate)
      const h = encoderOutputs; // Approximate h, c as single output for basic

      const decoderInputs = tf.input({shape: [maxLen], name: 'decoder_input'});
      let decoderEmbedding = tf.layers.embedding({
        inputDim: vocabSize,
        outputDim: embedDim,
        inputLength: maxLen,
        name: 'decoder_embedding'
      }).apply(decoderInputs);
      const decoderLSTM = tf.layers.lstm({
        units: hiddenDim,
        returnSequences: true,
        dropout: 0.2,
        name: 'decoder_lstm'
      });
      const decoderOutputs = decoderLSTM.apply(decoderEmbedding); // Initial state approx from encoder h
      const dense = tf.layers.dense({
        units: vocabSize,
        activation: 'softmax',
        name: 'dense'
      });
      const outputs = dense.apply(decoderOutputs);

      const model = tf.model({
        inputs: [encoderInputs, decoderInputs],
        outputs
      });
      model.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });
      return model;
    }

    // Load Seq2Seq from saved
    async function loadSeq2SeqModel(saved) {
      const model = createSeq2SeqModel(saved.vocabSize, saved.embedDim, saved.lstmUnits, saved.maxLen);
      const weightTensors = saved.weights.map(arr => tf.tensor(arr));
      model.setWeights(weightTensors);
      weightTensors.forEach(t => t.dispose());

      const wordToIdx = new Map();
      saved.vocab.forEach((word, idx) => wordToIdx.set(word, idx));
      const idxToWord = new Map([...wordToIdx.entries()].map(([k, v]) => [v, k]));
      return { model, wordToIdx, idxToWord };
    }

    // Custom loader for all model types
    async function loadModelFromSaved(saved) {
      if (!saved.vocab || !saved.weights) {
        throw new Error('Missing model components (vocab or weights). Retrain in dashboard.');
      }

      let model;
      if (saved.modelType === 'classifier') {
        if (!saved.inputDim || !saved.numClasses) {
          throw new Error('Missing classifier params (inputDim, numClasses).');
        }
        model = tf.sequential({
          layers: [
            tf.layers.dense({ inputShape: [saved.inputDim], units: 64, activation: 'relu' }),
            tf.layers.dropout({ rate: 0.2 }),
            tf.layers.dense({ units: saved.numClasses, activation: 'softmax' })
          ]
        });
      } else if (saved.modelType === 'lstm') {
        if (!saved.vocabSize || !saved.maxLen || !saved.numClasses) {
          throw new Error('Missing LSTM params (vocabSize, maxLen, numClasses).');
        }
        model = tf.sequential({
          layers: [
            tf.layers.embedding({
              inputDim: saved.vocabSize,
              outputDim: saved.embedDim || 32,
              inputLength: saved.maxLen
            }),
            tf.layers.lstm({
              units: saved.lstmUnits || 64,
              dropout: 0.2
            }),
            tf.layers.dense({ units: saved.numClasses, activation: 'softmax' })
          ]
        });
      } else if (saved.modelType === 'seq2seq') {
        if (!saved.vocabSize || !saved.maxLen) {
          throw new Error('Missing Seq2Seq params (vocabSize, maxLen).');
        }
        const seqStuff = await loadSeq2SeqModel(saved);
        return { model: seqStuff.model, ...seqStuff, vocabSize: saved.vocabSize, maxLen: saved.maxLen };
      }
      model.compile({
        optimizer: 'adam',
        loss: 'categoricalCrossentropy',
        metrics: ['accuracy']
      });

      // Set the trained weights
      const weightTensors = saved.weights.map(arr => tf.tensor(arr));
      model.setWeights(weightTensors);
      weightTensors.forEach(t => t.dispose());

      return model;
    }

    // Load the pre-trained TF model
    async function loadModel() {
      elements.modelProgress.value = 60;
      updateModelStatus('Loading Vynix AI model...');
      const modelRef = ref(db, 'models/current-model');
      onValue(modelRef, async (snapshot) => {
        const data = snapshot.val();
        console.log('Raw model data from RTDB:', data);  // Debug log
        if (!data || !data.vocab) {
          updateModelStatus('No trained model found. Using basic responses.');
          elements.modelProgress.value = 100;
          vynixModel = null;
          return;
        }

        // Check for updates
        if (data.timestamp <= lastModelTimestamp) return;
        lastModelTimestamp = data.timestamp;

        try {
          updateModelStatus('Preparing model...');
          elements.modelProgress.value = 80;

          // Load using custom function
          const loadedModel = await loadModelFromSaved(data);
          vynixModel = { 
            model: loadedModel, 
            vocab: data.vocab, 
            ...(data.uniqueAnswers ? { uniqueAnswers: data.uniqueAnswers } : {}),
            modelType: data.modelType,
            ...(data.modelType === 'lstm' ? { maxLen: data.maxLen, vocabSize: data.vocabSize } : {}),
            ...(data.modelType === 'seq2seq' ? { 
              wordToIdx: loadedModel.wordToIdx, 
              idxToWord: loadedModel.idxToWord,
              maxLen: data.maxLen, 
              vocabSize: data.vocabSize 
            } : {})
          };

          elements.modelProgress.value = 100;
          const version = data.version || '1.0';
          updateModelStatus(`Vynix ${data.modelType.toUpperCase()} loaded! v${version}`);

          // Notification
          elements.retrainNotification.textContent = `Vynix ${data.modelType.toUpperCase()} updated! ðŸ§ `;
          elements.retrainNotification.classList.remove('hidden');
          setTimeout(() => elements.retrainNotification.classList.add('hidden'), 3000);

          console.log('Model loaded successfully');
        } catch (error) {
          console.error('Detailed model load error:', error);
          updateModelStatus('Model load failed. Check console.');
          vynixModel = null;
          showError(`AI model failed: ${error.message}. Basic mode active.`);
        }
      }, (error) => {
        console.error('Model fetch error:', error);
        updateModelStatus('Failed to fetch model.');
      });
    }

    function startNewConversation() {
      messages = [];
      elements.chatMessages.innerHTML = '';
      elements.welcomeContainer.classList.remove('hidden');
      hasChatted = false;
      elements.newConversationButton.classList.add('hidden');
    }

    elements.sendButton.addEventListener('click', sendMessage);

    elements.userInput.addEventListener('keypress', (e) => {
      if (e.key === 'Enter') sendMessage();
    });

    elements.newConversationButton.addEventListener('click', startNewConversation);

    onAuthStateChanged(auth, async (user) => {
      currentUser = user;
      if (user) {
        elements.loadingText.textContent = 'Connected! Initializing Vynix...';
        elements.modelProgress.value = 20;
        await tf.ready();  // Ensure TF.js ready
        loadTrainingData();  // Fallback
        loadModel();  // Main model
        setTimeout(() => {
          elements.loadingOverlay.classList.add('hidden');
          elements.inputContainer.classList.remove('hidden');
          elements.welcomeContainer.innerHTML = `<span class="material-icons" style="font-size: 24px; color: var(--bbm-red);">smart_toy</span>Hi! I'm Vynix, your AI companion. Ask me anything!`;
        }, 2500);
      } else {
        elements.loadingText.innerHTML = 'Not connected. <button class="btn" onclick="signInAnonymously()" style="background: var(--bbm-red); color: white; border: none; padding: 8px 16px; border-radius: 4px; cursor: pointer;">Connect Anonymously</button>';
      }
    });

    window.signInAnonymously = async function() {
      try {
        await signInAnonymously(auth);
      } catch (error) {
        showError('Connection failed: ' + error.message);
      }
    };

    window.signOutUser = async function() {
      try {
        await signOut(auth);
      } catch (error) {
        showError('Disconnect failed: ' + error.message);
      }
    };

    // Initial load
    elements.loadingOverlay.classList.remove('hidden');
    elements.loadingText.textContent = 'Initializing...';
    elements.modelProgress.value = 0;
  </script>
</body>
</html>
